{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork():    \n",
    "    \n",
    "     def __init__(self, d,d1,d2,d3): \n",
    "        \n",
    "        \"\"\"\n",
    "        d = number of neurons in the input vector/layer\n",
    "        d1 = number of neurons in the first hidden layer\n",
    "        d2 = number of neurons in the second hidden layer\n",
    "        d3 = number of neurons in the third hidden layer\n",
    "        the network outputs single value\n",
    "        \n",
    "        \"\"\"\n",
    "        # hyperparameters\n",
    "        self.d=d     \n",
    "        self.d1=d1\n",
    "        self.d2=d2\n",
    "        self.d3=d3\n",
    "        # weights\n",
    "        self.W1=2*np.random.uniform(0,1,(self.d1,self.d))-1\n",
    "        self.W2=2*np.random.uniform(0,1,(self.d2,self.d1))-1\n",
    "        self.W3=2*np.random.uniform(0,1,(self.d3,self.d2))-1\n",
    "        self.W4=2*np.random.uniform(0,1,(1,self.d3))-1\n",
    "        # biases \n",
    "        self.b1=2*np.random.uniform(0,1,(self.d1,1))-1\n",
    "        self.b2=2*np.random.uniform(0,1,(self.d2,1))-1\n",
    "        self.b3=2*np.random.uniform(0,1,(self.d3,1))-1\n",
    "        self.b4=2*np.random.uniform(0,1)-1\n",
    "        \n",
    "     def forward_pass (self, minibatch):\n",
    "        \"\"\"\n",
    "        minibatch : each row corresponds to a point, thus for m points the shape should be (m,d) \n",
    "        in case of single point the shape should be (1,d)\n",
    "        The function outputs the forward propagation pass of the network on each minibatch point \n",
    "        \"\"\"\n",
    "        size = minibatch.shape[0]\n",
    "        minibatch_values = np.zeros(size)\n",
    "        \n",
    "        net_layer1 = self.W1 @ minibatch.T + self.b1\n",
    "        layer1 = np.maximum(net_layer1,0)\n",
    "        net_layer2 = self.W2 @ layer1 + self.b2\n",
    "        layer2 = np.maximum(net_layer2,0)\n",
    "        net_layer3 = self.W3 @ layer2 + self.b3\n",
    "        layer3 = np.maximum(net_layer3,0)\n",
    "        minibatch_values = self.W4 @layer3 + self.b4\n",
    "        \n",
    "        net_layers = [net_layer1, net_layer2, net_layer3]\n",
    "        layers = [layer1, layer2, layer3]\n",
    "        \n",
    "        return minibatch_values, net_layers, layers\n",
    "    \n",
    "     def backpropagation(self, minibatch, targets):\n",
    "\n",
    "        size = minibatch.shape[0]\n",
    "        minibatch_values, net_layers, layers = self.forward_pass(minibatch)\n",
    "        \n",
    "        delta4 = 2*(minibatch_values - targets)\n",
    "        dW4 = delta4 @ layers[2].T /size\n",
    "        db4 = np.sum(delta4) /size\n",
    "        \n",
    "        delta3 = delta4.T @ self.W4 * np.where(net_layers[2]>=0,1,0).T\n",
    "        dW3 = delta3.T @ layers[1].T / size\n",
    "        db3 = np.sum(delta3) / size\n",
    "        \n",
    "        delta2 = delta3 @ self.W3 * np.where(net_layers[1]>=0,1,0).T\n",
    "        dW2 = delta2.T @ layers[0].T / size\n",
    "        db2 = np.sum(delta2) / size \n",
    "        \n",
    "        delta1 = delta2 @ self.W2 * np.where(net_layers[0]>=0,1,0).T\n",
    "        dW1 = delta1.T @ minibatch / size\n",
    "        db1 = np.sum(delta1) / size \n",
    "\n",
    "        return dW4, dW3, dW2, dW1, db4, db3, db2, db1 \n",
    "    \n",
    "     def draw_random_minibatch(self, dataset, minibatch_size):\n",
    "         j = np.random.choice(dataset.shape[0],minibatch_size,False) \n",
    "         random_minibatch =  dataset[j]\n",
    "         return j, random_minibatch\n",
    "    \n",
    "     def sgd(self, x_train, y_train, learning_rate, minibatch_size, iterations) :\n",
    "        \n",
    "        for i in range(iterations):\n",
    "        \n",
    "            j,B = self.draw_random_minibatch(x_train, minibatch_size)\n",
    "            \n",
    "            f_B = self.forward_pass(B)\n",
    "            \n",
    "            dW4, dW3, dW2, dW1, db4, db3, db2, db1 = self.backpropagation(B, y_train[j]) \n",
    "            \n",
    "            self.W1 = self.W1 - learning_rate * dW1\n",
    "            self.W2 = self.W2 - learning_rate * dW2\n",
    "            self.W3 = self.W3 - learning_rate * dW3\n",
    "            self.W4 = self.W4 - learning_rate * dW4\n",
    "            self.b4 = self.b4 - learning_rate * db4\n",
    "            self.b3 = self.b3 - learning_rate * db3\n",
    "            self.b2 = self.b2 - learning_rate * db2\n",
    "            self.b1 = self.b1 - learning_rate * db1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
